train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = d,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
class(Default$student)
class(d$student)
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
dft_train_fit = glm(default ~ income:student, balance:student, data = Default,
subset = train, family = binomial)
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
train_logistic_1 = function() {
train = sample(n_obs, n_obs/2);
dft_train_fit = glm(default ~ income + balance + student, data = Default,
subset = train, family = binomial)
test_default = Default[-train,]
test.probs = predict(dft_train_fit, test_default, type = "response");
def_pred = rep("No", length(train));
def_pred[test.probs > 0.5] = "Yes";
test_err = round(mean(def_pred != Default$default[-train]), 4)
test_err
}
err = train_logistic()
err
set.seed(123)
err = train_logistic() # error does not decrease
err
set.seed(234);
err = train_logstic()
set.seed(123)
err = train_logistic_1() # error does not decrease
err
set.seed(345);
train_logistic() # 0.027 error
set.seed(345);
train_logistic_1() # 0.027 error
set.seed(234);
err = train_logistic_1()
set.seed(123)
err1 = train_logistic_1()
err1
set.seed(234);
err2 = train_logistic_1()
err2
set.seed(345);
err3 = train_logistic_1() # 0.027 error
err3
glm_dir = glm(Direction ~ Lag1 + Lag2, data = Weekly, family = binomial)
summary(glm_dir)
glm_dir1 = glm(Direction ~ Lag1 + Lag2, data = Weekly[-1,], family = binomial)
summary(glm_dir)
ob1.prob = predict(dft_train_fit, Weekly[1,], type = "response");
ob1.prob = predict(glm_dir1, Weekly[1,], type = "response");
ob1.prob
Weekly[1,]$Direction
ob1.prob = predict(glm_dir1, Weekly[1,], type = "response") > 0.5# 0.5714 -> Up
ob1.prob
n = dim(Weekly)[1]
n
err = rep(0, n);
head(err)
dim(err)
err[1]
View(Weekl;y)
View(Weekly)
dir = predict(glm_dir1, Weekly[1,], type = "response") > 0.5
dir
if (pred_i == TRUE) {
dir = "Up"
} else {
dir = "Down"
}
pred_i = predict(glm_dir1, Weekly[1,], type = "response") > 0.5
if (pred_i == TRUE) {
dir = "Up"
} else {
dir = "Down"
}
error = (dir == Weekly[i,]$Direction)
if (pred_i == TRUE) {
dir = "Up"
} else {
dir = "Down"
}
error = (dir == Weekly[1,]$Direction)
error
if (pred_i == TRUE) {
dir = "Up"
} else {
dir = "Down"
}
dir
error = as.numeric((dir != Weekly[1,]$Direction))
error
n = dim(Weekly)[1]
err = rep(0, n);
for (i in c(1:n)) {
train = Weekly[-i,] # leave out i-th observation
# train model using the new training set
train.fit = glm(Direction ~ Lag1 + Lag2, data = train, family = binomial)
# predict i-th  observation
pred_i = predict(train.fit, Weekly[i,], type = "response") > 0.5
if (pred_i == TRUE) {
dir = "Up"
} else {
dir = "Down"
}
# store indicator for error
err[i] = as.numeric((dir != Weekly[i,]$Direction))
}
sum(err)
dim(Weeky)
dim(Weekly)
total_errors = sum(err);
total_errors
mean(total_errors)
mean(total_errors)
mean(err)
ob1.prob = predict(glm_dir1, Weekly[1,], type = "response") > 0.5
Weekly[1,]$Direction # Down -> incorrectly classified
avg_error    = mean(err)
avg_error
avg_error    = round(mean(err), 4)
avg_error
mean(err)
n
d = data.frame(x, y)
set.seed(1)
y = rnorm(100)
x = rnorm(100)
y = x - 2 * x^2 + rnorm(100)
# n = 100 observations, p = 2 predictors
# Y = X - 2X + epsilon
# (b)
d = data.frame(x, y)
d
head(d)
ggplot(d, aes(x, y)) + geom_point()
library(ggplo0t2)
library(ggplot2)
ggplot(d, aes(x, y)) + geom_point()
o1.fit = glm(y ~ x, data = d)# order 1 model
o1.fit = glm(y ~ x, data = d);          # order 1 model
o2.fit = glm(y ~ poly(x, 2), data = d); # order 2 model
o3.fit = glm(y ~ poly(x, 3), data = d); # order 3 model
o4.fit = glm(y ~ poly(x, 4), data = d); # order 4 model
?cv.glm
?cv
?cv
?cv.glm
library(boot)
?cv.glm
set.seed(1)
cv_err = rep(0, 4);
for (i in c(1:4)) {
fit_order_i = glm(y ~ poly(x, i), data = d);
cv_err[i] = cv.glm(d fit_order_i);
}
set.seed(1)
cv_err = rep(0, 4);
for (i in c(1:4)) {
fit_order_i = glm(y ~ poly(x, i), data = d);
cv_err[i] = cv.glm(d, fit_order_i);
}
set.seed(1)
cv_err = rep(0, 4);
for (i in c(1:4)) {
fit_order_i = glm(y ~ poly(x, i), data = d);
cv_err[i] = cv.glm(d, fit_order_i)$delta[1];
}
cv_err
cv_err1 = rep(0, 4);
for (i in c(1:4)) {
fit_order_i = glm(y ~ poly(x, i), data = d);
cv_err1[i] = cv.glm(d, fit_order_i)$delta[1];
}
cv_err1
set.seed(111)
cv_err1 = rep(0, 4);
for (i in c(1:4)) {
fit_order_i = glm(y ~ poly(x, i), data = d);
print(summary(fit_order_i));
cv_err1[i] = cv.glm(d, fit_order_i)$delta[1];
}
x = summary(fit_order_i)
x
x$coefficients
summary(fit_order_i)
cv_err
cv_err = round(cv_err, 4)
cv_err
?cv.glm
ggplot(d, aes(x, y)) + geom_point() # quadratic plot, where x in [-2, 2]
